\documentclass[../main.tex]{subfiles}
\begin{document}
\clearpage
\section{Асимптотика множеств достижимости на малом интервале времени и синтез управлений}

Вторая глава посвящена исследованию асимптотических свойств множеств достижимости нелинейных систем с интегральными ограничениями на малом промежутке времени и решению задачи синтеза на малом промежутке времени. 

В первом разделе продолжается анализ множеств достижимости нелинейных систем с интегральными ограничениями на управление на малых промежутках времени, начатый в Разделе \ref{s1:small_time_subsection}. 
Исследуется более общий случай множеств достижимости по выходу.
Такая постановка включает в себя множества достижимости по состоянию и их проекции.
Исследована близость множеств достижимости нелинейных систем и множеств достижимости линеаризованных систем при стремлении к нулю интервала времени. 
Для описания этой близости введено понятие асимптотической эквивалентности, основанное на расстоянии Банаха-Мазура. 
Использование этого расстояния оказывается удобно, так как это расстояние определяется именно формой множеств и отражает различие в форме даже для достаточно малых множеств. 
Использование метрики Хаусдорфа сопряжено с некоторыми трудностями, так как при стремлении длины промежутка времени к нулю, множества достижимости  превращаются в точки, и расстояние Хаусдорфа будет стремиться к нулю независимо от формы множеств.
Установлены достаточные условия асимптотической эквивалентности множеств достижимости нелинейных систем соответствующим множествам достижимости линеаризованных систем.
Как и в условии, полученном в Разделе \ref{s1:small_time_subsection}, в этом условии проверяется асимптотика наименьшего собственное число грамиана управляемости линеаризованной системы с малым параметром.

В разделе представлены примеры, включающие две нелинейные системы третьего порядка, в одной из которых линеаризованная вдоль траектории, порожденной нулевым управлением, система неуправляема, а в другом управляема.
Для этих систем исследованы достаточные условия выпуклости проекций множеств достижимости. 
Проведено численное моделирование, продемонстрировавшее невыпуклость некоторых проекций даже для малых длин временного промежутка.

Второй раздел посвящен задаче синтеза обратной связи для нелинейной аффинной по управлению системы. 
Целью управления является приведение траектории замкнутой системы в начало координат. 
Объектом изучения является нелинейная система, замкнутая линейной обратной связью. 
Эта обратная связь является решением линейно-квадратичной задачи для линеаризованной системы. 

Фактически, исследуется применимость метода линеаризации к задаче синтеза оптимального управления на конечном интервале времени. 
Показано, что лиинейная обратная связь, расчитанная для линеаризованной системы, также обеспечивает локальное решение задачи синтеза для нелинейной системы, если промежуток времени достаточно мал.   
Для этого требуются достаточно строгие ограничения на асимптотику грамиана управляемости, которые совпадают с достаточными условиями, обеспечивающими асимптотическую эквивалентность множеств достижимости (множеств нуль-управляемости). 
При этих условиях получена оценка для относительных значений погрешности интегрального функционала. 
Для демонстрации реализации описанного метода синтеза приведен пример нелинейной упругой системы под действием внешней силы. 

%Раздел организован следующим образом. 
%В первом подразделе приводится формулировка задачи и некоторые предварительные результаты. 
%Во втором подразделе 
%Следующий подраздел содержит результаты, относящиеся к асимптотике траекторий нелинейной системы, замкнутой линейной обратной связью. 
%Четвертый подраздел посвящен оценке погрешностей в значении функционала при использовании линейной обратной связи. 
%Наконец, в последнем подразделе приведены два иллюстративных примера.

\subsection{Асимптотика множеств достижимости нелинейных систем с интегральными ограничениями} 


\subsubsection{Расстояние Банаха-Мазура и асимптотическая эквивалентность множеств}\label{sec21:AsymptoticEquality}

Рассмотрим выпуклые компактные множества $ X,Y \subset \mathbb R^n $, такие, что $0 \in \operatorname{int}\ X$, $0 \in \operatorname{int}\ Y$. Тогда определена величина $r(X, Y) = \inf \{t \geq 1: tX \supset Y \}$. Расстоянием Банаха-Мазура  будем называть величину $ \rho (X, Y)  $, определенную равенством 
\begin{gather*}
    \rho (X, Y): = \log (r(X,Y) \cdot r(Y, X)).
\end{gather*}

Это определение является частным случаем определения расстояния Банаха-Мазура между нормированными пространствами \cite[Определение 2.4.6]{Thompson}.

Проверим, что величина $ \rho (X, Y)$ удовлетворяет аксиомам метрики. 
Напомним, что аксиомы метрики $\rho$ на множестве $\mathcal{X}$ таковы:
\begin{enumerate}
	\item Неотрицательность. $\rho(X,Y) \geqslant 0$.
	\item Тождественность.  $\rho(X,Y) = 0 $ тогда и только тогда, когда $X = Y$.
	\item Симметрия. $ \rho(X,Y) = \rho(Y,X) $.
	\item Неравенство треугольника.  $ \rho(X,Z) \leqslant \rho(X,Y) + \rho(Y,Z) $.
\end{enumerate}

Проверим каждую из них. 
Убедимся, что верна аксиома неотрицательности. 
По определению, $r(X,Y) \geqslant 1$. 
Аналогично, $ r(Y,X) \geqslant 1  $. 
Следовательно, 
\begin{gather*}
	r(X,Y)\cdot r(Y,X)  \geqslant 1  \qquad \Rightarrow \qquad
	 \log(r(X,Y) \cdot r(Y,X)) \geqslant \log(1) = 0.
\end{gather*}

Таким образом, $ \rho(X,Y) \geqslant 0 $.


Теперь проверим аксиому тождественности нулю.
Заметим, что $\rho(X,Y) = 0 $ тогда и только тогда, когда $ r(X,Y) \cdot r(Y,X) = 1$.
Так как $r(X,Y) \geqslant 1 $ и $r(Y,X) \geqslant 1 $, равенство достигается только в случае $r(X,Y) = r(Y,X) = 1 $.
Это означает, что
\begin{gather*}
	\inf\{t \geqslant 1 : tX \supset Y \} = 1, \\ 
	\inf\{t \geqslant 1 : tY \supset X \} = 1.
\end{gather*}

Условие  $ r(X,Y)=1$ означает $X \supset Y$, а  $r(Y,X)=1$, то есть  $Y \supset X$. 
Вместе они дают $X=Y$.
Обратное тоже верно: если $X=Y$, то  $r(X,Y)=r(Y,X)=1$, значит $\rho(X,Y)=0$.
Таким образом, тождественность нулю выполняется.

Перейдем к проверке симметрии. 
По определению 
\begin{gather*}
	\rho(X,Y)= \log(r(X,Y) \cdot r(Y,X)).
\end{gather*}

Меняя местами $X$ и $Y$, получаем:
$\rho(Y, X) = \log(r(Y,X) \cdot r(X,Y))=\rho(X,Y).$
Симметрия выполнена.

Наконец проверим неравенство треугольника. 
Нужно показать, что выполняется
\begin{gather*}
	\rho(X,Z) \geqslant \rho(X,Y) + \rho(Y,Z).
\end{gather*}
Подставив определения, получаем
\begin{gather*}
	\log(r(X,Z) \cdot r(Z,X)) \geqslant \log(r(X,Y) \cdot r(Y,X)) + \log(r(Y,Z) \cdot r(Z,Y)).
\end{gather*}
Экспоненцируем обе части неравенства, приходим к
\begin{gather}\label{s2:triangle_axiom}
	r(X,Z) \cdot r(Z,X) \leqslant r(X,Y) \cdot r(Y,X) \cdot r(Y,Z) \cdot r(Z,Y).
\end{gather}
Заметим, что $r(X,Z) \geqslant r(X,Y) \cdot r(Y,Z)$.
Действительно, пусть $ r(X,Y) = t $ и $r(Y,Z) = s$.
Тогда выполняются включения $tX \supset Y$, $sY \supset Z$.
Подставляя одно в другое, получаем $Z \subset sY \subset s(tX) = (st) X$.
Аналогично, можно показать, что $r(Z,X) \leqslant r(Z,Y) \cdot r(Y,X)$. 
Перемножая два этих неравенства, получаем искомое \eqref{s2:triangle_axiom}.

Таким образом, четыре аксиомы метрики выполнены, следовательно, $\rho(X,Y)$ действительно является расстоянием (метрикой) на множестве выпуклых компактных множеств с нулем во внутренности.

%\todo[inline]{Описать преимущества расстояния Банаха Мазура для малых множеств. Пример с кругом и квадратом. Посмотреть статью МИ в УМЖ}

Пусть $ X = X(\varepsilon) $,  $ Y = Y(\varepsilon) $ -- выпуклые компактные множества, такие, что $ 0 \in \operatorname{int}\,X(\varepsilon) $, $ 0 \in \operatorname{int}\,Y(\varepsilon) $ при $0 \leqslant \varepsilon \leqslant \overline{\varepsilon} $.
Тогда, следуя \cite{Ovs}, назовем множества $  X(\varepsilon)  $ и $  Y(\varepsilon) $ {\textit асимптотически эквивалентными}, если $  \rho (X(\varepsilon), Y(\varepsilon)) \rightarrow 0 $ при $\varepsilon \rightarrow 0 $.

Приведем далее достаточное условие асимптотической эквивалентности, выраженное через хаусдорфово расстояние $ h $ между ними.
\begin{theorem}\label{suff}\cite{GusevUMJ}
     Пусть выполнены условия:
    \begin{gather*}
        \lim\limits_{\varepsilon \rightarrow 0}h(X(\varepsilon),Y(\varepsilon)) = 0, \qquad    \lim\limits_{\varepsilon \rightarrow 0}\frac{h(X(\varepsilon),Y(\varepsilon))}{\delta_{min}(Y(\varepsilon))} = 0.
    \end{gather*}
    Тогда множества $ X(\varepsilon) $ и $ Y(\varepsilon) $\---~асимптотически эквивалентны. 
    
    Здесь $ \delta_{min}(Y(\varepsilon)) = \inf\limits_{\left\|y \right\| =1 } \delta(y|Y(\varepsilon))$, а $ \delta(y|Y(\varepsilon)) $ --- опорная функция\footnote{
    Опорной функцией множества $M$ называется функция $\delta(y|M) = \sup\limits_{x \in M} y^{\top} x$. 
    } множества $ Y(\varepsilon) $.
\end{theorem}
\subsubsection{Достаточное условие асимптотической эквивалентности множеств достижимости нелинейной и линеаризованной систем}
    Рассмотрим нелинейную систему \eqref{s1:common_nonlinear_small_time} с выходом
\begin{gather}\label{s2:nonlinear_with_output}
    \begin{gathered}
        \dot{x}(t)=f_1(t,x(t))+f_2(t,x(t))u(t), \qquad t_0 \leqslant t \leqslant t_0 + \overline{\varepsilon}, \qquad x(t_0) = x_0, \\
        y(t) = C x(t).
    \end{gathered}
\end{gather}

Здесь $ x \in \mathbb{R}^n $ -- вектор состояния, $ u \in \mathbb{R}^r $ -- управление,  $ y\in\mathbb{R}^m (m \leqslant n) $ -- выход системы,
$ C\in \mathbb{R}^{m \times n} $  -- матрица полного ранга,  $ \bar{\varepsilon} $ --- некоторое фиксированное положительное число.

Как и в предыдущих разделах функции $ f_1: [t_0, t_0 + \bar{\varepsilon}] \times \mathbb{R}^{n} \rightarrow \mathbb{R}^{n} $, $ f_2: [t_0, t_0 + \bar{\varepsilon}] \times \mathbb{R}^{n} \rightarrow \mathbb{R}^{n \times r} $ предполагаются непрерывными по $(x, t)$ и обладающими непрерывными производными по $x$ на $ [t_0, t_0 + \bar{\varepsilon}]$. 

Принятые в предыдущих разделах Предположения \ref{s1:as:right_hand_side_conditions_global} и \ref{s1:as:right_hand_side_diff_lip} относительно функций $f_1$ и $f_2$ будем считать справедливыми на интервале $t_0 \leqslant t \leqslant t_0 + \overline{\varepsilon} $ при управлениях $u(\cdot) \in B_{\mathbb{L}_2}(0, \overline{\mu}) $, $\overline{\mu} > 0$.

 Управление $u(t)$ будем выбирать из
пространства $\mathbb{L}_2[t_0,t_0+\bar{\varepsilon}]$ вектор-функций и ограничим его шаром радиуса $ 0 < \mu \leqslant \overline{\mu} $
\begin{gather}\label{constrY}
    \lVert u(\cdot)\rVert^2_{\mathbb{L}_2} = \left(u(\cdot),u(\cdot) \right) \leqslant \mu^2.
\end{gather}

Пусть $ 0 <  \varepsilon \leqslant \bar{\varepsilon} $. 

Множеством достижимости системы \eqref{s2:nonlinear_with_output} по состоянию, как и прежде, будем называть множество 
\begin{gather*}
    G(\varepsilon)=\{x\in \mathbb{R}^n:\exists u(\cdot)\in B_{\mathbb{L}_2}(0,\mu),\; x=x(t_0+\varepsilon, u(\cdot))\}.
\end{gather*}


\begin{definition}
    {\textit Множеством достижимости $\overline{G}(\varepsilon)$ системы \eqref{s2:nonlinear_with_output} по выходу} $ y = C x $ будем называть множество всех выходов $ y(t_0+\varepsilon) $,
    соответствующих концам траекторий $ x(t_0+\varepsilon, u(\cdot)) $, порождённых управлениями $ u(\cdot) \in B_{\mathbb{L}_2}(0,\mu)$
    \begin{gather*}
        \overline{G}(\varepsilon)=\{y\in \mathbb{R}^m:\exists u(\cdot)\in B_{\mathbb{L}_2}(0,\mu),\; y=Cx(t_0+\varepsilon, u(\cdot))\}.
    \end{gather*}
\end{definition}

В определениях множеств, приведённых выше, можно считать, что $ \mathbb{L}_2 =\mathbb{L}_2[t_0,t_0+\varepsilon] $, либо  $ \mathbb{L}_2=\mathbb{L}_2[t_0,t_0+\bar{\varepsilon}] $.
Нетрудно понять, что для любого из этих пространств мы получаем одно и то же множество достижимости. 
%Будем далее считать, что $ \mathbb{L}_2 =\mathbb{L}_2[t_0,t_0+\varepsilon] $.
    
Заметим, что  $ \overline{G}(\varepsilon) = C G(\varepsilon) $.    
    
Если матрица $ C \in \mathbb{R}^{m \times n} $ такова, что в каждой её строке только один элемент равен 1, а остальные равны 0, а в каждом столбце содержится не более одного ненулевого элемента, то $ y=Cx $ состоит из $ m$ координат вектора $ x $, а  множество достижимости $\overline{G}(\varepsilon)$ представляет собой проекцию множества $ G(\varepsilon) $ на $m$--мерную координатную плоскость. 
Возможен случай $C = I$, в этом случае $y = x$ и $ \overline{G}(\varepsilon) = G(\varepsilon)$


\begin{definition}
    Симметричная матрица, определённая равенством
    \begin{gather*}
        \overline{W}(t_0 + \varepsilon) = \int_{t_0}^{t_0+\varepsilon} C X(t_0+\varepsilon,t)B(t)B^{\top}(t)X^{\top}(t_0+\varepsilon,t) C^\top \, dt=CW(\varepsilon)C^\top,
    \end{gather*}
    называется грамианом управляемости линейной системы 
    \begin{gather}\label{s2:linear_system}
    	\dot{s} = A(t) s + B(t) u
    \end{gather}
    на интервале времени $  t_0 \leqslant t \leqslant t_0 + \varepsilon $ по выходу $y = C z$. 
    Как и в определении \ref{s1:def:linearized_system} здесь $X(\tau_1, \tau_0) = \Phi(\tau_1) \Phi^{−1}(\tau_0)$, где $\Phi(\tau)$ ---
    фундаментальная матрица решений однородной системы, удовлетворяющая уравнению
    $\Phi(t) = A(t) \Phi(t)$, $\Phi(t_0) = I$.
\end{definition}
    
Система \eqref{s2:linear_system} управляема (вполне управляема) на  $ [t_0, t_0 + \varepsilon] $ по выходу $y=Cx$ тогда и только тогда,
когда  грамиан управляемости по выходу $ \overline{W}(t_0 + \varepsilon) = C W(t_0 + \varepsilon) C^{\top}  $ -- положительно определенная матрица.
   
   
По аналогии с \eqref{s1:eps_nonlinear}, произведем замену времени $t = \varepsilon \tau + t_0$, примем обозначения $z(\tau) = x(\varepsilon \tau + t_0)$, $ \upsilon(\tau) = \varepsilon u(\varepsilon \tau + t_0) $ и $h(\tau) = y(\varepsilon \tau + t_0)$ и получим из \eqref{s2:nonlinear_with_output}
\begin{gather}\label{s2:eps_nonlinear_with_output}
\begin{gathered}
	\dot{z}(\tau)=\widetilde{f}_1(\tau,z(\tau))+\widetilde{f}_2(\tau,z(\tau))\upsilon(\tau), \qquad 0 \leqslant \tau \leqslant 1, \qquad z(0) = x_0, \\
	h(\tau) = C z(\tau).
\end{gathered}
\end{gather}

Обозначим $\mathbb{L}_2 = \mathbb{L}_2[0, 1]$. 

Как и в \eqref{s1:common_nonlinear_small_time}, здесь $ \widetilde{f}_1(\tau,z) = \varepsilon f_1(\varepsilon \tau + t_0, z) $, $ \widetilde{f}_2 (\tau,z) = f_2(\varepsilon \tau + t_0,z)$, а управление $ \upsilon(\cdot) \in B_{\mathbb{L}_2}(0, \mu\sqrt{\varepsilon})$.
Система \eqref{s2:eps_nonlinear_with_output} наследует и другие свойства системы \eqref{s1:eps_nonlinear}.
Для каждого $\upsilon(\cdot) \in B_{\mathbb{L}_2} (0, \overline{\mu} \sqrt{\varepsilon})$ существует единственное решение \eqref{s2:eps_nonlinear_with_output}  $z(\cdot, \upsilon(\cdot))$, определенное на интервале $\tau \in [0,1]$. 
Для системы \eqref{s2:eps_nonlinear_with_output} справедливы Предположение \ref{s1:as:right_hand_side_conditions_global} в области $[0, 1]\times D$ и при $\upsilon(\cdot) \in B_{\mathbb{L}_2}(0, \overline{\mu}\sqrt{\varepsilon}) $ и 
Лемма \ref{s1:lem:lip_of_solutions_global}.

Обозначим через $\overline{G}_{\varepsilon}(\tau)$ множество достижимости системы \eqref{s2:eps_nonlinear_with_output} по выходу $h$ в момент времени $\tau$
\begin{gather*}
	\overline{G}_{\varepsilon}(\tau)=\{h\in \mathbb{R}^m:\exists \upsilon(\cdot)\in B_{\mathbb{L}_2}(0,\mu\sqrt{\varepsilon}),\; h=Cz(\tau,\upsilon(\cdot))\}.
\end{gather*}

Продолжая по аналогии с \eqref{s1:eps_linearized}, выпишем линейную систему, соответствующую линеаризации системы  \eqref{s2:eps_nonlinear_with_output} вдоль пары $(z(\cdot, 0), 0)$ 
\begin{gather}\label{s2:eps_linearized}
\begin{gathered}
	\delta\dot{z} = A_{\varepsilon}(\tau) \delta z(\tau) + B_{\varepsilon}(\tau) \delta \upsilon(t),\qquad 0 \leqslant \tau \leqslant 1,  \qquad \delta z(0) = 0, \\
	\delta h(\tau) = C \delta z(\tau).
\end{gathered}
\end{gather}

Как и в \eqref{s1:eps_linearized}, здесь 
\begin{gather*}
	A_{\varepsilon}(\tau) = \dfrac{\partial \widetilde{f}_1}{\partial z} \Big(\tau, z\big(\tau, 0 \big)\Big) = \varepsilon \dfrac{\partial f_1}{\partial x} \Big(\varepsilon \tau + t_0 ,x\big(\varepsilon \tau + t_0, 0\big)\Big),  \\
	B_{\varepsilon}(\tau) = \widetilde{B}_{\varepsilon}(\tau, 0) = \widetilde{f}_2 \Big(\tau,z\big(\tau, 0\big)\Big) = f_2 \Big(\varepsilon \tau + t_0, x\big(\varepsilon \tau + t_0, 0\big)\Big).
\end{gather*}  

Для фундаментальной матрицы и грамиана управляемости системы \eqref{s2:eps_linearized} продолжим использовать обозначения  $ X_{\varepsilon}(\tau,\xi) $ $(X_{\varepsilon}(\tau, \xi, \upsilon(\cdot)))$ и $W_{\varepsilon}(\tau)$ соответственно. 
Грамиан управляемости системы \eqref{s2:eps_linearized} по выходу $ \delta h$ обозначим через $\overline{W}_{\varepsilon}(\tau)$. 
Как и в разделе \ref{s1:small_time_subsection}, для $\tau = 1$ будем использовать сокращенные обозначения $W_{\varepsilon}(1) = W_{\varepsilon}$ и $\overline{W}_{\varepsilon}(1) = \overline{W}_{\varepsilon}$. 

Как и в предыдущем разделе, определим отображение $S: \mathbb{L}_2[0,1] \rightarrow \mathbb{R}^n $ равенством $S\upsilon(\cdot) = z(1,\upsilon(\cdot))$: здесь $ z(1,\upsilon(\cdot))$ ~--- решение системы \eqref{s2:eps_nonlinear_with_output}, порожденное управлением $\upsilon(\cdot)$. 

Учитывая, что функции  $\widetilde{f}_1$ и $\widetilde{f}_2$ удовлетворяют Предположению \ref{s1:as:right_hand_side_diff_lip} на множестве $[0, 1]\times D$, из Леммы \ref{s1:lem:frechet_derivative_common}  следует, что производная Фреше отображения $S$ существует и определяется равенством $ S'(\upsilon(\cdot))\delta \upsilon(\cdot) = \delta z(1)$, где $\delta z(t)$ ~--- решение линеаризованной вдоль пары $\big( z(\cdot,\upsilon(\cdot)),\upsilon(\cdot)\big)  $ системы \eqref{s2:eps_linearized}, порожденное управлением $\delta \upsilon(\cdot)$ при нулевых начальных условиях, то есть
\begin{gather}\label{s2:freсhet_differential_of_scaled_map}
	S'(\upsilon(\cdot))\delta \upsilon(\cdot) = \int\limits_0^1  X_{\varepsilon}(1, \tau, \upsilon(\cdot)) \widetilde{B}_{\varepsilon}(\tau, \upsilon(\cdot))  \delta\upsilon(\tau)\ d\tau. 
\end{gather}

 Теперь определим композицию отображений $ S $ и $ C $, $ H: \mathbb{L}_2[0,1]  \rightarrow \mathbb{R}^m $, есть $ H(\upsilon(\cdot)) = C S(\upsilon(\cdot)) = C z(1,\upsilon(\cdot)) $. 
Из $h(\tau) = y(\varepsilon \tau + t_0)$ при $ \upsilon(\tau) = \varepsilon u(\varepsilon \tau + t_0) $ следует, что  
\begin{gather*}
	H(B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon))) = \overline{G}_{\varepsilon}(1) = \overline{G}(\varepsilon), 
\end{gather*}
где $ \varrho(\varepsilon) = \mu \sqrt{\varepsilon} $.

Отображение $ H $ непрерывно дифференцируемо по Фреше при всех $ \upsilon(\cdot) \in  B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon)) $, как композиция непрерывно дифференцируемых отображений и его производная Фреше $ H': \mathbb{L}_2[0,1]  \rightarrow  \mathbb{R}^m $ определена равенством:
\begin{gather*}
	H'( \upsilon(\cdot))\delta \upsilon =  C S'(\upsilon(\cdot))\delta  \upsilon = C \delta z(1) = \delta h(1),
\end{gather*}
где $ \delta z(1) $ --- решение линеаризованной системы \eqref{s2:eps_linearized} c нулевыми начальными условиями и управлением $  \delta  \upsilon(\cdot) $. 
 Из \eqref{s2:freсhet_differential_of_scaled_map} следует, что дифференциал Фреше $ H'(\upsilon(\cdot)) \delta \upsilon(\cdot) $ есть ни что иное, как
\begin{gather*}
	H'(\upsilon(\cdot)) \delta \upsilon(\cdot) = C \int\limits_0^1 X_{\varepsilon}(1,\tau, \upsilon(\cdot)) \widetilde{B}_{\varepsilon} (\tau, \upsilon(\cdot)) \delta \upsilon(\tau) \ d \tau.
\end{gather*}

По аналогии с \eqref{s1:self_adjoint_with_derivative}, можно показать, что $ H'(0) H'(0)^* = \overline{W}_{\varepsilon}$. 
Отсюда следует, что управляемость системы \eqref{s2:eps_linearized} по выходу $\delta h$ (минимальное собственное число $\overline{\lambda}(\varepsilon)$ грамиана $ \overline{W}_{\varepsilon}$ должно быть строго положительно), означает регулярность отображения $H$ в точке $\upsilon = 0$.

Обозначим через $G^0_{\varepsilon}(\tau)$ и $\overline{G}^0_{\varepsilon}(\tau)$ множества достижимости системы \eqref{s2:eps_linearized} при $\delta \upsilon \in B_{\mathbb{L}_2}(0, \rho(\varepsilon))$ по состоянию и выходу соответственно.

\begin{lemma}
	Пусть система \eqref{s2:eps_linearized} вполне управляема при $\tau \in [0,1]$. 
	Тогда множества достижимости  $G^0_{\varepsilon}(\tau)$ и $\overline{G}^0_{\varepsilon}(\tau)$ --- эллипсоиды в $\mathbb{R}^n$ и $\mathbb{R}^m$ соответственно,
	\begin{gather*}
		 G^0_{\varepsilon}(\tau) = S'(0) B_{\mathbb{L}_2}(0,\mu\sqrt{\varepsilon}) =  \{ x \in \mathbb{R}^n: x^{\top} W^{-1}_{\varepsilon} x \leqslant \mu^2 \varepsilon \} = W^{1/2}_{\varepsilon} B_{\mathbb{R}^n}(0,\mu\sqrt{\varepsilon}), \\
		 \overline{G}^0_{\varepsilon}(\tau) = H'(0) B_{\mathbb{L}_2}(0,\mu\sqrt{\varepsilon}) =  \{ y \in \mathbb{R}^m: y^{\top} \overline{W}^{-1}_{\varepsilon} y \leqslant \mu^2 \varepsilon \} = \overline{W}^{1/2}_{\varepsilon} B_{\mathbb{R}^m}(0,\mu\sqrt{\varepsilon}).
	\end{gather*}
	Здесь $M^{1/2}$ ~--- арифметический квадратный корень из матрицы $M$, $ B_{\mathbb{R}^n}(0,\mu) $ ~--- евклидов шар радиуса $ \mu $ в $ \mathbb{R}^n $.
\end{lemma}
\doc
Равенства $G^0_{\varepsilon}(\tau) = S'(0) B_{\mathbb{L}_2}(0,\mu\sqrt{\varepsilon})$ и $ \overline{G}^0_{\varepsilon}(\tau) = H'(0) B_{\mathbb{L}_2}(0,\mu\sqrt{\varepsilon}) $, очевидно, следуют из определений отображений  $ S' $, $ H' $ и множеств $ G^0_{\varepsilon}(\tau)$, $ \overline{G}^0_{\varepsilon}(\tau)$.

Рассмотрим опорную функцию $\delta(l | G^0_{\varepsilon}(\tau))$. 
Множество $G^0_{\varepsilon}(\tau) = S'(0) B_{\mathbb{L}_2}(0,\mu\sqrt{\varepsilon})$  запишем в виде 
\begin{gather*}
	G^0_{\varepsilon}(\tau)  = \left\{ x \in \mathbb{R}^n: x = \int\limits_0^1  X_{\varepsilon}(1, \tau, \upsilon(\cdot)) \widetilde{B}_{\varepsilon}(\tau, \upsilon(\cdot))  u(\tau)\ d\tau, \ u(\cdot) \in B_{\mathbb{L}_2}(0,\mu\sqrt{\varepsilon}) \right\}.
\end{gather*} 
По определению
\begin{gather*}
	\delta(l | G^0_{\varepsilon}(\tau)) = \max\limits_{u(\cdot) \in B_{\mathbb{L}_2}(0,\mu\sqrt{\varepsilon})} l^{\top} \int\limits_0^1  X_{\varepsilon}(1, \tau, \upsilon(\cdot)) \widetilde{B}_{\varepsilon}(\tau, \upsilon(\cdot))  u(\tau)\ d\tau = \\ =
	\max\limits_{u(\cdot) \in B_{\mathbb{L}_2}(0,\mu\sqrt{\varepsilon})}  \int\limits_0^1  l^{\top} X_{\varepsilon}(1, \tau, \upsilon(\cdot)) \widetilde{B}_{\varepsilon}(\tau, \upsilon(\cdot))  u(\tau)\ d\tau  =\\=
	 \max\limits_{u(\cdot) \in B_{\mathbb{L}_2}(0,\mu\sqrt{\varepsilon})} \Big(\alpha(\cdot) , u(\cdot)\Big)_{\mathbb{L}_2} =
	 \mu\sqrt{\varepsilon} \| \alpha(\cdot)\|_{\mathbb{L}_2},
\end{gather*}
где $ \alpha(\tau) = \widetilde{B}^{\top}_{\varepsilon}(\tau, \upsilon(\cdot)) X^{\top}_{\varepsilon}(1, \tau, \upsilon(\cdot)) l$. 
Тогда,
\begin{gather*}
	\| \alpha(\cdot)\|^2_{\mathbb{L}_2} = l^{\top} \int\limits_0^1 X_{\varepsilon}(1, \tau, \upsilon(\cdot)) \widetilde{B}_{\varepsilon}(\tau, \upsilon(\cdot))  \widetilde{B}^{\top}_{\varepsilon}(\tau, \upsilon(\cdot)) X^{\top}_{\varepsilon}(1, \tau, \upsilon(\cdot)) \ d\tau \ l = l^{\top} W_{\varepsilon} l.
\end{gather*}
Итого, получаем $\delta(l | G^0_{\varepsilon}(\tau)) =  \mu\sqrt{\varepsilon} \sqrt{l^{\top} W_{\varepsilon} l}  $.

Теперь убедимся, что  $W^{1/2}_{\varepsilon} B_{\mathbb{R}^n}(0,\mu\sqrt{\varepsilon}) = \{ x \in \mathbb{R}^n: x^{\top} W^{-1}_{\varepsilon} x \leqslant \mu^2 \varepsilon \} $.
Перепишем первое множество в виде $ W^{1/2}_{\varepsilon} B_{\mathbb{R}^n}(0,\mu\sqrt{\varepsilon}) = \{ a \in \mathbb{R}^n: a = W^{1/2}_{\varepsilon} b, \ b^{\top} b  \leqslant \mu^2 \varepsilon, b \in \mathbb{R}^n \} $. 
Отсюда $b = W^{-1/2}_{\varepsilon} a $.
Тогда $ b^{\top} b = a^{\top} W^{-1}_{\varepsilon} a \leqslant \mu^2 \varepsilon $, что и требовалось показать.

Наконец, рассмотрим опорную функцию $\delta(l | W^{1/2}_{\varepsilon} B_{\mathbb{R}^n}(0,\mu\sqrt{\varepsilon}))$, по определению
\begin{gather*}
	\delta(l | W^{1/2}_{\varepsilon} B_{\mathbb{R}^n}(0,\mu\sqrt{\varepsilon})) = \max\limits_{x \in B_{\mathbb{R}^n}(0,\mu\sqrt{\varepsilon}))} l^{\top} W^{1/2}_{\varepsilon} x = \mu\sqrt{\varepsilon} \sqrt{l^{\top} W_{\varepsilon} l}.
\end{gather*}
Так как множества $W^{1/2}_{\varepsilon} B_{\mathbb{R}^n}(0,\mu\sqrt{\varepsilon}) $ и $S'(0) B_{\mathbb{L}_2}(0,\mu\sqrt{\varepsilon})$ выпуклы, из равенства их опорных функций следует равенство самих множеств. 
Аналогично доказывается равенство множеств $\overline{G}^0_{\varepsilon}(\tau) = H'(0) B_{\mathbb{L}_2}(0,\mu\sqrt{\varepsilon}) =  \{ y \in \mathbb{R}^m: y^{\top} \overline{W}^{-1}_{\varepsilon} y \leqslant \mu^2 \varepsilon \} = \overline{W}^{1/2}_{\varepsilon} B_{\mathbb{R}^m}(0,\mu\sqrt{\varepsilon})$

 \hfill $\square$
    
Основной результат этого раздела отражен в следующей теореме.
\begin{theorem}\label{s2:th:assimptotic_equality}
        При достаточно малых $ \varepsilon $ множество достижимости $ \overline{G}(\varepsilon) $ системы \eqref{s2:nonlinear_with_output} по выходу $ y = C x $ выпукло и асимптотически эквивалентно множеству $\overline{W}^{1/2}(\varepsilon)B_{\mathbb{R}^n}(0,\mu) + Cx(t_0+\varepsilon,0)$, если найдутся такие $ K>0 $, $ \alpha > 0 $, $ 0< \varepsilon_0<\overline{\varepsilon}  $, что для всех $ \varepsilon \leqslant \varepsilon_0 $
        \begin{gather}\label{cond1}
           \overline{\lambda}(\varepsilon) \geqslant \left\{ {\begin{array}{*{20}{l}}
                    {K\varepsilon ^{3 - \alpha}, \mbox{\ если \ } f_2(t,x) \mbox{\ не зависит от \ } x}, \\
                    {K\varepsilon ^{1 - \alpha}}, \mbox{\ в противном случае}.
            \end{array}} \right.
        \end{gather}
\end{theorem}
    
    \doc
    Применяя Лемму \ref{s1:lem:lip_dx_global} к отображению $S$, получаем, что его производная Фреше $S'(\upsilon)$ удовлетворяет условию Липшица
    при $ \upsilon \in B_{\mathbb{L}_2[0,1]}(0,\rho(\varepsilon))  $.
    Тогда и $ H'(\upsilon(\cdot)) $ --- липшицева, 
    \begin{gather*}
        \left\| H_{\varepsilon}'(\upsilon_1(\cdot)) - H'_{\varepsilon}(\upsilon_2(\cdot)) \right\| \leqslant L(\varepsilon) \left\| \upsilon_1(\cdot) - \upsilon_2(\cdot)\right\|,
    \end{gather*}
    где для константы Липшица $ L(\varepsilon) = L_0 + L_1 \varepsilon$ отображения $ H' $ сохраним то же обозначение, что и в Лемме \ref{s1:lem:lip_dx_global}.
    А неравенство \eqref{s1:th3_proof_origin_condition} перепишем так, чтобы найти условие, при котором множество достижимости системы \eqref{s2:nonlinear_with_output} по выходу $ \overline{G}(\varepsilon) = \overline{G}_{\varepsilon}(1) = H (B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon)))$ будет выпуклым:
    \begin{gather}\label{est2}
        4\varrho^2(\varepsilon)L^2(\varepsilon) = 4\mu^2\varepsilon L^2(\varepsilon) \leqslant \overline{\lambda}(\varepsilon),
    \end{gather}
    где $ \varrho(\varepsilon)  = \mu\sqrt{\varepsilon} $.
    
    В случае, если функция $ f_2(t,x) $ не зависит от $ x $, то $ L(\varepsilon) = L_1 \varepsilon  $, а \eqref{est2} принимает вид $ \overline{\lambda}(\varepsilon) \geqslant 4\mu^2L_1^2 \varepsilon^3 $.  Это неравенство будет выполнено, если $ K\varepsilon^{3 - \alpha} \geqslant 4\mu^2L_1^2 \varepsilon^3 $, что равносильно соотношению $ \varepsilon \geqslant \varepsilon_1 := \left(\frac{K}{4\mu^2L_1^2}\right)^{1/\alpha} $.  Таким образом, множество достижимости $ G_y(\varepsilon)$ выпукло при $ 0 \leqslant \varepsilon \leqslant \min\{\varepsilon_0,\varepsilon_1\}  $.  
    
    В другом случае, если $ f_2(t,x) $ зависит от $ x $, $ L(\varepsilon) =L_0+L_1\varepsilon $, а \eqref{est2} принимает вид $ \overline{\lambda}(\varepsilon) \geqslant 4\mu^2 \varepsilon (L_0 + L_1 \varepsilon)^2 $.  Учитывая, что $ \overline{\lambda}(\varepsilon)  \geqslant K \varepsilon^{1-\alpha} $, достаточно доказать, что $ K \varepsilon^{1-\alpha}  \geqslant 4\mu^2 \varepsilon (L_0 + L_1 \varepsilon_0)^2 $. Последнее неравенство выполняется при $ \varepsilon \leqslant \varepsilon_2 := \left(\frac{K}{4\mu^2(L_0 + L_1\varepsilon_0)^2} \right)^{1/\alpha} $. Следовательно, $ G_y(\varepsilon) $ выпукло, если $ 0 \leqslant \varepsilon \leqslant \min\{\varepsilon_0, \varepsilon_2\} $.
    
    Множество у $\overline{W}^{1/2}(\varepsilon)B_{\mathbb{R}^n}(0,\mu) + Cx(t_0+\varepsilon,0)  = H'(0)B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon))+ H(0)$ есть не что иное, как множество достижимости по выходу линеаризованной системы \eqref{s2:eps_linearized} с учетом сдвига, обусловленного свободным движением системы \eqref{s2:eps_nonlinear_with_output}.
    
    Доказательство асимптотической эквивалентности проекций множеств достижимости нелинейной и линеаризованной систем проводится по той же схеме, что и доказательство следствий теоремы 2 в \cite{GusevUMJ}. Оценим сверху хаусдорфово расстояние между образами гильбертова шара $ H\left( B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon))\right)  $ и $ H'(0)B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon))+ H_{\varepsilon}(0) $:
    \begin{gather*}
        h\left( \overline{G}(\varepsilon), H'(0)B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon))+ H(0)\right)  \leqslant L(\varepsilon) \varrho^2(\varepsilon).
    \end{gather*}
    А так как $ \lim\limits_{\varepsilon \rightarrow 0}  L(\varepsilon) \varrho^2(\varepsilon) = 0 $, то и $ \lim\limits_{\varepsilon \rightarrow 0} h\left( \overline{G}_y(\varepsilon), H'(0)B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon))+ H(0)\right)  = 0 $.
    
    
    Множество достижимости линеаризованной системы -- конечномерный эллипсоид и его наименьшая полуось $ \delta_{min}\left(H'(0)B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon)) \right)=\varrho(\varepsilon)\sqrt{\overline{\lambda}(\varepsilon)} $. 
    Следовательно,
    \begin{gather*}
        \frac{h\left(\overline{G}(\varepsilon), H'(0)B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon))+ H(0)\right) }{\delta_{min}\left( H'(0)B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon))\right) } \leqslant \frac{L(\varepsilon) \varrho(\varepsilon)}{\sqrt{\overline{\lambda}(\varepsilon)}}.
    \end{gather*}
    
    При выполнении условий теоремы в первом случае ($ f_2(t,x) $ не зависисит от $ x $) имеем
    \begin{gather*}
        \frac{L(\varepsilon) \varrho(\varepsilon)}{\sqrt{\overline{\lambda}(\varepsilon)}} 
        \leqslant
        \frac{L_1\varepsilon\mu\sqrt{\varepsilon}}{K^{\frac{1}{2}}\varepsilon^{\frac{3}{2}-\frac{\alpha}{2}}} 
        =
        L_1\mu K^{-\frac{1}{2}}\varepsilon^{\frac{\alpha}{2}} \rightarrow 0 \mbox{\ при\ } \varepsilon \rightarrow 0.
    \end{gather*}
    
    Во втором случае,
    \begin{gather*}
        \frac{L(\varepsilon) \varrho(\varepsilon)}{\sqrt{\overline{\lambda}(\varepsilon)}} 
        \leqslant
        \frac{(L_0+L_1\varepsilon)\mu\sqrt{\varepsilon}}{{K^{\frac{1}{2}}}\varepsilon^{\frac{1}{2}-\frac{\alpha}{2}}}
        =
        (L_0+L_1\varepsilon)\mu K^{-\frac{1}{2}}\varepsilon^{\alpha/2} \rightarrow 0 \mbox{\ при\ } \varepsilon \rightarrow 0.
    \end{gather*}
    
    Таким образом условия теоремы \ref{suff} выполнены, а значит множества $ \overline{G}(\varepsilon) $ и \\$ H'(0)B_{\mathbb{L}_2[0,1]}(0,\varrho(\varepsilon))+ H(0) $ асимптотически эквиваленты.
    \hfill $\square$
    \begin{utv}
        Пусть $ W_1 $, $ W $ -- симметричные матрицы, причем $ W_1 = C W C^{\top} $, где $ C $ -- матрица  полного ранга размерности $ m \times n $, $ m \leqslant n $, а $ \nu(W) $, $ \nu(W_1) $ и $ \nu(CC^{\top}) $ -- наименьшие собственные числа соответствующих матриц.
        
        Тогда
        \begin{gather*}
            \nu(W_1) \geqslant \nu(CC^{\top})  \nu(W).
        \end{gather*}
    \end{utv}
    \doc. 
    Действительно,
    \begin{gather*}
        \forall x \in \mathbb{R}^m, \: x^{\top} W_1 x = x^{\top} C W C^{\top} x \geqslant \nu(W)\left\| C^{\top}x \right\| ^2,\\
        \nu(W)\left\| C^{\top}x \right\| ^2 = \nu(W) x^{\top} C C^{\top} x
    \end{gather*}
    Следовательно,
    \begin{gather*}
        \nu(W_1) = \min \limits_{\left\| x\right\| =1}x^{\top}W_1x \geqslant \nu(W)\min \limits_{\left\| x\right\| =1}x^{\top}CC^{\top}x = \nu(CC^{\top})  \nu(W) 
    \end{gather*} \begin{flushright}
        \hfill $ \square $
    \end{flushright}
    
    Применяя утверждение к грамиану управляемости линеаризованной системы $ W_{\varepsilon} $, грамиану управляемости по выходу $ \overline{W}_{varepsilon}$, и их наименьшим собственным числам $ \overline{\lambda}(\varepsilon) $ и $ \lambda(\varepsilon) $, получим
    \begin{gather*}
        \overline{\lambda}(\varepsilon) \geqslant \nu(CC^{\top}) \lambda(\varepsilon),
    \end{gather*}
    где $ \nu(CC^{\top}) $ не зависит от $ \varepsilon $. 
    Значит асимптотика $ \overline{\lambda}(\varepsilon) $ при $\varepsilon \rightarrow 0$ не может быть хуже асимптотики $ \lambda(\varepsilon) $, если $ C $ -- матрица полного ранга. 
    Это соответствует очевидному факту, если множество $ G(\varepsilon) $ -- выпуклое, то и для всех возможных матриц полного ранга $ C $, соответствующие множества $ \overline{G}(\varepsilon) $ --- выпуклы. 
    Однако невыпуклое множество $ G(\varepsilon) $  может иметь выпуклые проекции, что продемонстрировано в одном из примеров.
    
\subsubsection{О выпуклости двумерных проекций множеств достижимости уницикла на малых промежутках времени}    
    Исследуем проекции множеств достижимости на примере системы третьего порядка
    \begin{gather}\label{unicycle0}
        \dot{x_1} = v(t)\cos(x_3), \qquad
        \dot{x_2} = v(t)\sin(x_3), \qquad
        \dot{x_3} = u(t), \qquad 0 \leqslant t \leqslant \varepsilon
    \end{gather}
    при ограничениях на управление 
    \begin{gather*}
        v(t) = 1, \qquad \int_0^1 u^2(t) \, dt \leqslant 1
    \end{gather*}
    и нулевых начальных условиях $ x_1(0) = x_2(0) = x_3(0) = 0 $.
    
    Система \eqref{unicycle0} известна как уницикл (при $ v(t) = 1$  --- машина Дубинса). При геометрическом
    ограничении на
    управление ($|u(t)|\leqslant 1$) проекции множества достижимости  машины Дубинса  на двумерное пространство координат $(x_1,\,x_2)$ были исследованы в
    \cite{Cockayne}. Общая трехмерная картина множества достижимости получена в
    работах \cite{Patsko} (при геометрических ограничениях), \cite{Patsko2023} (при интегральных ограничениях). Множество достижимости интегратора Брокетта, к которому нелинейными преобразованиями могут быть приведены уравнения уницикла \eqref{unicycle0}, исследовано в\cite{Vdovin}.
    
    Запишем решение $ x(t,u(t)) $, порожденное нулевым управлением $ u(t) \equiv 0 $:
    \begin{gather*}
        \begin{gathered}
            \dot{x_3} = 0 \longrightarrow x_3(t) = x_3(0) + 0 = 0, \\
            \dot{x_2} = \sin(x_3(t)) = \sin(0) \longrightarrow x_2(t) = x_2(0) + \int_0^t 0 \, d\tau = 0,\\
            \dot{x_1} = \cos(x_3(t)) = \cos(0) \longrightarrow x_3(t) = x_3(0) + \int_0^t    1 \, d\tau = t.
        \end{gathered}
    \end{gather*}
    Матрицы линеаризованной системы не зависят от $ t $ и имеют вид:
    \begin{gather}\label{linear0}
        A = \begin{pmatrix}
            0 & 0 & 0 \\ 
            0 & 0 & 1 \\ 
            0 & 0 & 0
        \end{pmatrix}, \qquad  B = \begin{pmatrix}
            0 \\ 
            0 \\ 
            1
        \end{pmatrix} 
    \end{gather}
    Пара $ (A,B) $, очевидно, не является вполне управляемой.
    Выпишем фундаментальную матрицу системы \eqref{linear0}, а затем получим грамиан управляемости линеаризованной системы
    \begin{gather*}
        \begin{gathered}
            \dot{X}(t,t_1) = A(t) X(t,t_1), \qquad X(t_1,t_1) = I \\
            X(t,\tau) = \begin{pmatrix}
                1 & 0 & 0 \\ 
                0 & 1 & \varepsilon \\ 
                0 & 0 & 1
            \end{pmatrix}  \\
            W(\varepsilon) = \int_0^{\varepsilon}X(\varepsilon,t) B B^{\top} X^{\top}(\varepsilon,t)dt 
            =\begin{pmatrix}
                0 & 0 & 0 \\
                0 & \frac{\varepsilon^3}{3} & \frac{\varepsilon^2}{2} \\
                0 &  \frac{\varepsilon^2}{2} & \varepsilon
            \end{pmatrix} 
        \end{gathered}
    \end{gather*}
    Сделаем замену времени и перепишем грамиан управляемости в виде
    \begin{gather*}
        \widetilde{W}(\varepsilon) = \frac{1}{\varepsilon}W(\varepsilon)     =\begin{pmatrix}
            0 & 0 & 0 \\
            0 & \frac{\varepsilon^2}{3} & \frac{\varepsilon}{2} \\
            0 &  \frac{\varepsilon}{2} & 1
        \end{pmatrix} 
    \end{gather*} 
    Теперь последовательно рассмотрим проекции системы \eqref{unicycle0} на координатные плоскости $ (x_1, x_2) $, $ (x_1, x_3) $, $ (x_2, x_3) $. \\
    
    \begin{enumerate}
        \item Рассмотрим плоскость $ (x_1, x_2) $. Матрица $ C $ для этой проекции имеет вид
        \begin{gather*}
            C = \begin{pmatrix}
                1 & 0 & 0 \\
                0 & 1 & 0
            \end{pmatrix}.
        \end{gather*}
        Грамиан управляемости в нормированном времени
        \begin{gather*}
            \widetilde{W}_{x_1,x_2}(\varepsilon) =  C \widetilde{W} (\varepsilon) C^{\top}  =\begin{pmatrix}
                0 & 0 \\
                0 & \frac{\varepsilon^2}{3}. \\
            \end{pmatrix}.
        \end{gather*}
        Нетрудно заметить, что $ \widetilde{W}_{x_1,x_2}(\varepsilon) $ -- вырожденная. Следовательно, система \eqref{unicycle0} не управляема по выходу $ (x_1, x_2) $, а значит, достаточное условие выпуклости множества достижимости по выходу $ G_{x_1,x_2}(\varepsilon) $ не выполняется. Множество $ G_{x_1,x_2}(\varepsilon) $ полученное в численном эксперименте показано на рисунке~\ref{fig:RS}-\subref{fig:u=0_x1-x2}. Отметим, что в разделе \ref{s1:examples}, при помощи принципа максимума доказано, что $ G(\varepsilon) $ -- невыпукло. Из данного доказательства также следует, что $ G_{x_1,x_2}(\varepsilon) $ тоже не является выпуклой.
        
        В этой работе для построения множеств достижимости мы используем алгоритм, основанный на методе Монте-Карло. %\todo{тут  будет ссылка либо на статью Игоря, либо на раздел, когда он появится}\footnote{Zykof2}.
        Удовлетворяющее интегральным ограничениям управление $ u(t) $ представляется в виде линейной комбинации ортогональных полиномов. Коэффициенты этого разложения -- равномерно распределенные случайные нормированные векторы. Перебирая такие векторы, будем получать программные управления, удовлетворяющие ограничениям \eqref{constr}. Концы траекторий, порожденные такими управлениями, покрывают множество достижимости.
        
        
        \item Теперь рассмотрим проекцию на плоскость $ (x_1, x_3) $. Выпишем матрицы $ C $ и $ \widetilde{W}_{x_1,x_3}(\varepsilon) $
        \begin{gather*}
            C = \begin{pmatrix}
                1 & 0 & 0 \\
                0 & 0 & 1
            \end{pmatrix}, \qquad
            \widetilde{W}_{x_1,x_3}(\varepsilon) =  C \widetilde{W} (\varepsilon) C^{\top}  =\begin{pmatrix}
                0 & 0 \\
                0 & 1 \\
            \end{pmatrix} .
        \end{gather*}
        Ситуация аналогична предыдущему случаю: матрица $ \widetilde{W}_{x_1,x_3}(\varepsilon)  $ вырождена, достаточное условие выпуклости не выполняется. Результат численного моделирования приведен на рисунке~\ref{fig:RS}-\subref{fig:u=0_x1-x3}.
        \item Наконец, перейдем к плоскости $ (x_2, x_3) $. Здесь
        \begin{gather*}
            C = \begin{pmatrix}
                0 & 1 & 0 \\
                0 & 0 & 1
            \end{pmatrix}, \qquad \widetilde{W}_{x_2,x_3}(\varepsilon) =  C \widetilde{W} (\varepsilon) C^{\top}  =\begin{pmatrix}
                \frac{\varepsilon^2}{3} & \frac{\varepsilon}{2} \\
                \frac{\varepsilon}{2} & 1
            \end{pmatrix}.
        \end{gather*}
        В этом случае матрица $ \widetilde{W}_{x_2,x_3}(\varepsilon) $ не вырождена и ее минимальное собственное число $ \nu^{x_2,x_3} = \frac{\varepsilon^2}{12} + O(\varepsilon^4)  $ удовлетворяет критерию \eqref{cond1} при достаточно малых $ \varepsilon $ и множество достижимости по выходу $ G_{x_2,x_3}(\varepsilon) $, как следует из теоремы \ref{th2}, выпукло и асимптотически эквивалентно соответствующему множеству достижимости линеаризованной системы, что и проиллюстрировано на рисунке~\ref{fig:RS}-\subref{fig:u=0_x2-x3}. Пунктирной линией на рисунке показана точная граница множества достижимости линеаризованной системы, сдвинутая на $ Cx(\varepsilon, 0) $. Из рисунка видно, что эта граница (эллипс) практически совпадает с границей множества достижимости нелинейной системы.
    \end{enumerate} 
    
    \begin{figure}[ht!] 
        \hspace{-2.5ex}
        \begin{minipage}[b]{.49\linewidth} 
            \small
            \centering 
            \includegraphics[width=\linewidth]{images/OsipovI_u=0_x1-x2.eps}
            %\input{OsipovI_u=0_x1-x2_0.tex}
            \subcaption{$ G_{x_1, x_2}(\varepsilon) $ системы \eqref{unicycle0};}
            \label{fig:u=0_x1-x2} 
        \end{minipage}
        \hfill
        \begin{minipage}[b]{.49\linewidth} 
            \small
            \centering
            \includegraphics[width=\linewidth]{images/OsipovI_u=1_x1-x2.eps}
            %\input{OsipovI_u=1_x1-x2_0.tex}
            \subcaption{$ G_{x_1, x_2}(\varepsilon) $ системы \eqref{unicycle1};}
            \label{fig:u=1_x1-x2}  
        \end{minipage} 
        \vfill
        \hspace{-2.5ex}
        \begin{minipage}[b]{.49\linewidth} 
            \small
            \centering 
            \includegraphics[width=\linewidth]{images/OsipovI_u=0_x1-x3.eps}
            %\input{OsipovI_u=0_x1-x3_0.tex}
            \subcaption{$ G_{x_1, x_3}(\varepsilon) $ системы \eqref{unicycle0};}
            \label{fig:u=0_x1-x3} 
        \end{minipage}
        \hfill
        \begin{minipage}[b]{.49\linewidth} 
            \small
            \centering
            \includegraphics[width=\linewidth]{images/OsipovI_u=1_x1-x3.eps}
            %\input{OsipovI_u=1_x1-x3_0.tex}
            \subcaption{$ G_{x_1, x_3}(\varepsilon) $ системы \eqref{unicycle1};}
            \label{fig:u=1_x1-x3}  
        \end{minipage} 
        \vfill
        \hspace{-2.5ex}
        \begin{minipage}[b]{.49\linewidth} 
            \small
            \centering 
            \includegraphics[width=\linewidth]{images/OsipovI_u=0_x2-x3.eps}
            %\input{OsipovI_u=0_x2-x3_0.tex}
            \subcaption{$ G_{x_2, x_3}(\varepsilon) $ системы \eqref{unicycle0};}
            \label{fig:u=0_x2-x3} 
        \end{minipage}
        \hfill
        \begin{minipage}[b]{.49\linewidth} 
            \small
            \centering
            \includegraphics[width=\linewidth]{images/OsipovI_u=1_x2-x3.eps}
            %\input{OsipovI_u=1_x2-x3_0.tex}
            \subcaption{$ G_{x_2, x_3}(\varepsilon) $ системы \eqref{unicycle1};}
            \label{fig:u=1_x2-x3}  
        \end{minipage}
        \caption{Результаты численного эксперимента для $ \varepsilon = 0.01 $.}\label{fig:RS}
    \end{figure}
    
    Немного изменим рассмотренный пример для того, чтобы линеаризованная система оставалась управляемой. Итак, рассматривается нелинейная система
    \begin{gather}\label{unicycle1}
        \dot{x_1} = \cos(x_3), \qquad
        \dot{x_2} = \sin(x_3), \qquad
        \dot{x_3} = 1 + u(t), \qquad 0 \leqslant t \leqslant \varepsilon
    \end{gather}
    при интегральных ограничениях на управление 
    \begin{gather*}
        \int_0^1 u^2(t) dt \leqslant 1
    \end{gather*}
    и нулевых начальных условиях $ x_1(0) = x_2(0) = x_3(0) = 0 $. Фактически, это то же самое, что рассматривать исходную систему при ограничении $ \displaystyle{\int_0^1} \left( u(t) - 1\right)^2 \ dt \leqslant 1$.
    
    Порождённое нулевым управлением $ u(t) \equiv 0 $ решение обозначим $ x(t,0) = x(t) $ и будем использовать его как опорное. 
    \begin{gather}\label{trj}
        \begin{gathered}
            \dot{x_3} = 1 \longrightarrow x_3(t) = x_3(0) + t = t, \\
            \dot{x_2} = \sin(x_3(t)) = \sin(t) \longrightarrow x_2(t) = x_2(0) + \int_0^t \sin(\tau) d\tau = 1 - \cos(t),\\
            \dot{x_1} = \cos(x_3(t)) = \cos(t) \longrightarrow x_1(t) = x_1(0) + \int_0^t \cos(\tau) d\tau = \sin(t).
        \end{gathered}
    \end{gather}
    Выпишем матрицы линеаризованной вдоль траектории \eqref{trj} системы 
    \begin{gather*}
        A(t) = \begin{pmatrix}
            0 & 0 & -\sin(t) \\ 
            0 & 0 & \cos(t) \\ 
            0 & 0 & 0
        \end{pmatrix}, \qquad  B = \begin{pmatrix}
            0 \\ 
            0 \\ 
            1
        \end{pmatrix}.
    \end{gather*}
    Для изучения грамиана управляемости выпишем фундаментальную матрицу линеаризованной системы
    \begin{gather*}
        \begin{gathered}
            X(t,\tau) = \begin{pmatrix}
                1 & 0 & \cos(t)-\cos(t_1) \\ 
                0 & 1 & \sin(t)-\sin(t_1) \\ 
                0 & 0 & 1
            \end{pmatrix}.
        \end{gathered}    
    \end{gather*}
    Грамиан управляемости имеет вид
    \begin{gather*}
        W(\varepsilon) = \int_0^{\varepsilon}X(\varepsilon,t) B B^{\top} X^{\top}(\varepsilon,t)dt =
    \end{gather*}
    \begin{gather*}
        =\begin{pmatrix}
            \varepsilon-\dfrac{3}{4} \sin(2\varepsilon) +\dfrac{1}{2}\varepsilon \cos(2\varepsilon)& \dfrac{3}{2}\cos^2(\varepsilon) - \cos(\varepsilon) + \dfrac{1}{2}\varepsilon \sin(2 \varepsilon) - \dfrac{1}{2} &  \varepsilon\cos( \varepsilon)-\sin( \varepsilon) \\[8pt] 
            * & \dfrac{3}{4}\sin(2\varepsilon) + \dfrac{1}{2}\varepsilon + \varepsilon \sin^2(\varepsilon) - 2 \sin(\varepsilon) & \cos(\varepsilon) + \varepsilon\sin(\varepsilon)-1 \\ 
            * & * & \varepsilon
        \end{pmatrix}.    
    \end{gather*}
    Здесь и далее, будем заменять элементы симметричных матриц под главной диагональю на $ * $ для лаконичной записи.
    Проделаем замену времени $ t = \varepsilon \tau $ и выпишем грамиан управляемости $ \widetilde{W}(\varepsilon) $ линеаризованной системы в новом времени $ \tau $
    \begin{gather*}
        \widetilde{W}(\varepsilon) = \dfrac{1}{\varepsilon} W(\varepsilon) = 
    \end{gather*} \footnotesize
    \begin{gather*}
        =\begin{pmatrix} 
            \cos^2(\varepsilon)-\dfrac{3}{4\varepsilon}\sin(2\varepsilon)+\dfrac{1}{2} & 
            \cos\left(\varepsilon \right)\,\sin\left(\varepsilon \right)+\dfrac{1}{2\,\varepsilon}\left( 3\cos^2\left(\varepsilon \right)-2\cos\left(\varepsilon\right)-1\right) &
            \cos\left(\varepsilon \right)-\dfrac{1}{\varepsilon} \sin\left(\varepsilon \right) \\[8pt] 
            * &
            \dfrac{3}{2}-\dfrac{2\,\sin\left(\varepsilon \right)-\dfrac{3\,\cos\left(\varepsilon \right)\,\sin\left(\varepsilon \right)}{2}}{\varepsilon }-{\cos\left(\varepsilon \right)}^2 & \sin\left(\varepsilon \right)+\dfrac{1}{\varepsilon } \left(\cos\left(\varepsilon \right)-1 \right)\\
            * &
            * & 
            1 \end{pmatrix}.    
    \end{gather*}
    \normalsize
    Далее последовательно рассмотрим проекции системы \eqref{unicycle1} на координатные плоскости $ (x_1, x_2) $, $ (x_1, x_3) $, $ (x_2, x_3) $. \\
    
    \begin{enumerate}
        \item Будем рассматривать проекцию $ G_{x_1, x_2}(\varepsilon) $ области достижимости системы \eqref{unicycle1} на плоскость первых двух фазовых координат. Матрица проектирования будет иметь вид
        \begin{gather*}
            C = \begin{pmatrix}
                1 & 0 & 0 \\ 
                0 & 1 & 0 
            \end{pmatrix}. 
        \end{gather*} 
        Тогда: \small
        \begin{gather}\label{Ve}
            \widetilde{W}_{x_1,x_2}(\varepsilon)= \begin{pmatrix}
                \cos^2(\varepsilon)-\dfrac{3}{4\varepsilon}\sin(2\varepsilon)+\dfrac{1}{2} & 
                \cos\left(\varepsilon \right)\,\sin\left(\varepsilon \right)+\dfrac{1}{2\,\varepsilon}\left( 3\cos^2\left(\varepsilon \right)-2\cos\left(\varepsilon\right)-1\right) \\[6pt]
                * &
                \dfrac{3}{2}-\dfrac{1}{\varepsilon }\left(2\,\sin\left(\varepsilon \right)-\dfrac{3\,\cos\left(\varepsilon \right)\,\sin\left(\varepsilon \right)}{2} \right) -{\cos\left(\varepsilon \right)}^2 
            \end{pmatrix}
        \end{gather}
        \normalsize
        Для исследования асимптотики $ \nu^{x_1,x_2}(\varepsilon) $ -- минимального собственного числа $ \widetilde{W}_{x_1,x_2}(\varepsilon) $, перепишем \eqref{Ve}, разложив тригонометрические функции в ряд вблизи точки $ \varepsilon = 0 $.
        \begin{gather*}
            \widetilde{W}_{x_1,x_2}(\varepsilon) = \begin{pmatrix}
                \dfrac{2\,\varepsilon ^4}{15} + O(\varepsilon^6)&
                -\dfrac{5\,\varepsilon ^3}{24} + O(\varepsilon^5)\\[8pt]
                -\dfrac{5\,\varepsilon ^3}{24} + O(\varepsilon^5) & 
                \dfrac{\varepsilon ^2}{3}-\dfrac{3\,\varepsilon ^4}{20} + O(\varepsilon^6).
            \end{pmatrix}.
        \end{gather*}
        
        Минимальное собственное число $ \nu^{x_1,x_2}(\varepsilon) = \frac{1}{120}\varepsilon^4 + O(\varepsilon^6)$, а $ \varepsilon^4 < \varepsilon^{3-\alpha} $ для всех $ \alpha > 0 $ при достаточно малых $ \varepsilon $, то есть достаточное условие выпуклости $ G_{x_1, x_1}(\varepsilon) $ не выполняется. Результаты численного моделирования, приведённые на рисунке~\ref{fig:RS}-\subref{fig:u=1_x1-x2}, показывают невыпуклость проекции. 
        \item Перейдем к плоскости $ (x_1,x_3) $. 
        \begin{gather*}
            C = \begin{pmatrix}
                1 & 0 & 0 \\
                0 & 0 & 1
            \end{pmatrix}, \qquad
            \widetilde{W}_{x_2,x_3}(\varepsilon) =  C \widetilde{W} (\varepsilon) C^{\top}  = \\ =\begin{pmatrix}
                \cos^2(\varepsilon)-\dfrac{3}{4\varepsilon}\sin(2\varepsilon)+\dfrac{1}{2} & 
                \cos\left(\varepsilon \right)-\dfrac{1}{\varepsilon} \sin\left(\varepsilon \right) \\ 
                * & 1
            \end{pmatrix}.
        \end{gather*}
        Так же, как и в случае плоскости $ (x_1,x_2) $ разложим компоненты $     \widetilde{W}_{x_1,x_3}(\varepsilon)  $ в ряд вблизи точки $ \varepsilon = 0 $:
        \begin{gather*}
            \widetilde{W}_{x_1,x_3}(\varepsilon) = \begin{pmatrix} 
                \dfrac{2\,\varepsilon ^4}{15} + O(\varepsilon^6) &
                -\dfrac{\varepsilon^2}{3}+ O(\varepsilon ^4)\\[8pt]
                -\dfrac{\varepsilon^2}{3} + O(\varepsilon^4) & 1 \end{pmatrix}.
        \end{gather*}
        Минимальное собственное число матрицы $  \widetilde{W}_{x_1,x_3}(\varepsilon)  $, $ \nu^{x_1,x_3} =   \frac{1}{45}\varepsilon^4 + O(\varepsilon^6) $, также не удовлетворяет условию \eqref{cond1}. Соответствующий результат численного построения проекции множества достижимости показан на рисунке~\ref{fig:RS}-\subref{fig:u=1_x1-x3}.
        \item Последний случай -- плоскость $ (x_2,x_3) $.
        \begin{gather*}
            C = \begin{pmatrix}
                0 & 1 & 0 \\
                0 & 0 & 1
            \end{pmatrix}, \qquad
            \widetilde{W}_{x_2,x_3}(\varepsilon) =  C \widetilde{W} (\varepsilon) C^{\top}  =\\=\begin{pmatrix}
                \dfrac{3}{2}-\dfrac{2\,\sin\left(\varepsilon \right)-\dfrac{3\,\cos\left(\varepsilon \right)\,\sin\left(\varepsilon \right)}{2}}{\varepsilon }-{\cos\left(\varepsilon \right)}^2 & \sin\left(\varepsilon \right)+\dfrac{1}{\varepsilon } \left(\cos\left(\varepsilon \right)-1 \right)\\[8pt]
                * & 
                1 
            \end{pmatrix}.
        \end{gather*}
        Точно также разложим $ \widetilde{W}_{x_2,x_3}(\varepsilon) $ в ряд
        \begin{gather*}
            \widetilde{W}_{x_2,x_3}(\varepsilon)  = \begin{pmatrix}
                \dfrac{\varepsilon^2}{3} + O(\varepsilon^4) &
                \dfrac{\varepsilon }{2} + O(\varepsilon^3) \\[8pt]
                \dfrac{\varepsilon }{2} + O(\varepsilon^3) & 1
            \end{pmatrix}
        \end{gather*}
        Минимальное собственное число в этом случае равно $ \nu^{x_2,x_3}(\varepsilon) = \frac{\varepsilon^2}{12} + O(\varepsilon^4) $, то есть удовлетворяет условию \eqref{cond1}. Выпуклость этой проекции проиллюстрирована на рисунке~\ref{fig:RS}-\subref{fig:u=1_x2-x3}.  Как и на рисунке~\ref{fig:RS}-\subref{fig:u=0_x2-x3}, здесь пунктирной линией показана точная граница множества достижимости линеаризованной системы.
    \end{enumerate}
\end{document}